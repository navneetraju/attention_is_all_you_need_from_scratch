{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Transformer Encoder-Decoder Demo\n",
    "#### We are just trying to see if we get an \"output\" from the model. Remember this is model is untrained, we are seeing if the model can run without errors and if it produce \"words\", its like seeing if an infant can babble."
   ],
   "id": "77a4b8eacbdb20d4"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-11T17:29:21.414301Z",
     "start_time": "2025-04-11T17:29:21.411307Z"
    }
   },
   "source": [
    "import torch\n",
    "\n",
    "from modules.transformer import TransformerEncoderDecoder"
   ],
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Here we are defining a basic vocabulary for source and target languages\n",
    "##### The most important thing here is the <start>, <end>, and <pad> tokens, because they are used to mark the beginning and end of sentences and for padding. And also its the \"trigger\" for the model to start and stop generating."
   ],
   "id": "12c65351deca45b9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T17:28:28.272605Z",
     "start_time": "2025-04-11T17:28:28.269811Z"
    }
   },
   "cell_type": "code",
   "source": [
    "src_vocab = {\"<pad>\": 0, \"<start>\": 1, \"<end>\": 2, \"hello\": 3, \"llms\": 4, \"are\": 5, \"great\": 6}\n",
    "tgt_vocab = {\"<pad>\": 0, \"<start>\": 1, \"<end>\": 2, \"hi\": 3, \"there\": 4, \"llms\": 5, \"are\": 6, \"awesome\": 7}"
   ],
   "id": "37215095b5b81f45",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Here we define a simple tokenize function to convert sentences into token IDs based on the vocabulary",
   "id": "2e822aa33ae70f66"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T17:28:28.707052Z",
     "start_time": "2025-04-11T17:28:28.703589Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tokenize(sentence, vocab):\n",
    "    tokens = sentence.lower().split()\n",
    "    return [vocab.get(token, vocab[\"<pad>\"]) for token in tokens]"
   ],
   "id": "5dc90dfc9ad6698c",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Now we will create a source and target sentence and convert them into token IDs",
   "id": "6ef6d9a6fa802c80"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T17:28:29.398019Z",
     "start_time": "2025-04-11T17:28:29.394563Z"
    }
   },
   "cell_type": "code",
   "source": [
    "src_sentence = \"<start> hello llms <end>\"\n",
    "tgt_sentence = \"<start>\""
   ],
   "id": "3080a950649f6610",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T17:28:29.872063Z",
     "start_time": "2025-04-11T17:28:29.867821Z"
    }
   },
   "cell_type": "code",
   "source": [
    "src_ids = torch.tensor([tokenize(src_sentence, src_vocab)], dtype=torch.long)\n",
    "tgt_ids = torch.tensor([tokenize(tgt_sentence, tgt_vocab)], dtype=torch.long)\n",
    "\n",
    "print(f\"Source IDs: {src_ids}\")\n",
    "print(f\"Target IDs: {tgt_ids}\")"
   ],
   "id": "46cd5e9d9a18be75",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source IDs: tensor([[1, 3, 4, 2]])\n",
      "Target IDs: tensor([[1]])\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Here we set up the model parameters and instantiate the Transformer model",
   "id": "aa03f8cd7b32f487"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T17:28:30.688731Z",
     "start_time": "2025-04-11T17:28:30.684710Z"
    }
   },
   "cell_type": "code",
   "source": [
    "src_vocab_size = len(src_vocab)\n",
    "tgt_vocab_size = len(tgt_vocab)\n",
    "max_seq_length = 10\n",
    "embedding_dim = 32\n",
    "num_encoder_layers = 2\n",
    "num_decoder_layers = 2\n",
    "num_heads = 4\n",
    "feed_forward_dim = 64"
   ],
   "id": "44270301a6543141",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T17:28:31.458637Z",
     "start_time": "2025-04-11T17:28:31.447391Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = TransformerEncoderDecoder(\n",
    "    src_vocab_size=src_vocab_size,\n",
    "    tgt_vocab_size=tgt_vocab_size,\n",
    "    max_seq_length=max_seq_length,\n",
    "    embedding_dim=embedding_dim,\n",
    "    num_encoder_layers=num_encoder_layers,\n",
    "    num_decoder_layers=num_decoder_layers,\n",
    "    num_heads=num_heads,\n",
    "    feed_forward_dim=feed_forward_dim\n",
    ")"
   ],
   "id": "900de4a1cfd3eb54",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Now we will run the model to generate output logits",
   "id": "84df4b39c9df4859"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T17:28:32.296073Z",
     "start_time": "2025-04-11T17:28:32.273701Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 5: Generate output (random at this stage, since the model is untrained)\n",
    "## Run until we get <end> token or max length\n",
    "outputs = []\n",
    "while True:\n",
    "    output_logits = model(src_ids, tgt_ids)\n",
    "    outputs.append(output_logits)\n",
    "    predicted_ids = torch.argmax(output_logits, dim=-1)\n",
    "    tgt_ids = torch.cat([tgt_ids, predicted_ids[:, -1:]], dim=1)\n",
    "    if predicted_ids[0, -1].item() == tgt_vocab[\"<end>\"] or tgt_ids.size(1) >= max_seq_length:\n",
    "        break"
   ],
   "id": "7570c7f677858e03",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T17:28:33.081399Z",
     "start_time": "2025-04-11T17:28:33.078058Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def decode_ids(ids, vocab):\n",
    "    inv_vocab = {v: k for k, v in vocab.items()}\n",
    "    return [inv_vocab.get(id.item(), \"<unk>\") for id in ids]"
   ],
   "id": "422116558bdd678e",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Now we will decode the predicted token IDs to see the output by just choosing the highest probability token. This is a simple way to see if the model can produce any output.\n",
    "##### Research has shown that this isnt the best way to generate text, but for this demo, we just want to see if the model can produce something."
   ],
   "id": "e596047f2726a845"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T17:28:34.152538Z",
     "start_time": "2025-04-11T17:28:34.148446Z"
    }
   },
   "cell_type": "code",
   "source": "decoded_sentence = \" \".join(decode_ids(tgt_ids[0], tgt_vocab))",
   "id": "d8e1d4e913631f3c",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T17:28:35.955070Z",
     "start_time": "2025-04-11T17:28:35.951825Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Input Sentence:\", src_sentence)\n",
    "print(\"Ouput Sentence:\", decoded_sentence)"
   ],
   "id": "2cf3e7157a2169ae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Sentence: <start> hello llms <end>\n",
      "Ouput Sentence: <start> <start> <start> llms llms llms llms awesome <end>\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### We got \"an\" output, which is a valid, as the words are from our vocabulary. This means the model can run without errors and produce some output. \n",
    "##### P.s Did you really expect it to produce something meaningful?"
   ],
   "id": "c9025e3b4c1aca4b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
